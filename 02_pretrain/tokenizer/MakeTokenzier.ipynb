{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27ee49-b0e0-4898-9f64-8de1fc33ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79492f9c-295c-497b-8834-f7c4187579a5",
   "metadata": {},
   "source": [
    "<h3>Loading CharBPETokenizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378e989-d807-4e30-a498-1e36f7dc9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers import CharBPETokenizer\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "from tokenizers.decoders import Metaspace as DecoderMetaspace\n",
    "\n",
    "tokenizer = CharBPETokenizer(suffix=\"\")\n",
    "\n",
    "pre_tokenizer = pre_tokenizers.Metaspace(\n",
    "    replacement=\"▁\",\n",
    "    prepend_scheme=\"always\",\n",
    "    split=True\n",
    ")\n",
    "decoder = DecoderMetaspace(\n",
    "    replacement=\"▁\",\n",
    "    prepend_scheme=\"always\",\n",
    "    split=True\n",
    ")\n",
    "\n",
    "tokenizer.pre_tokenizer = pre_tokenizer\n",
    "tokenizer.decoder = decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9d5b3-b1f8-45ca-8327-6aa63f367c77",
   "metadata": {},
   "source": [
    "<h3>Training Tokenizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8638e8-d76c-415f-a76c-2d3d338255bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files=[\"./datasets/training_texts.txt\"], vocab_size=50000, min_frequency=2, suffix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c73715-7cf4-42c6-998b-0cb1c0b8112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save('./ko_tokenizer/tokenizer.json')\n",
    "tokenizer.save('./ko_tokenizer/tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11724f4-c339-458c-b2f2-fb5aaf6e0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('./ko_tokenizer/tokenizer.json')\n",
    "tokenizer.save_pretrained('./ko_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1d3e4-8132-4903-a5da-c660848bdd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kogpt2_tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df9195-591c-4182-ae33-ef697d20c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./ko_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26792f3-d15a-48bd-b562-bb3c1dd0b8d9",
   "metadata": {},
   "source": [
    "<h3>Evaluating Tokenizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded0a9b-be2c-4a37-a493-b30d377d54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(tokenizer, input):\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    print(\"Tokens:\", tokens)\n",
    "    \n",
    "    # Decode the tokens back to text\n",
    "    decoded_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(tokens))\n",
    "    print(\"Decoded text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef025829-c393-4b62-97ff-4d59c35311b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text(tokenizer, \"'1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653fb15-1c14-42b5-a183-900e7fbfffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text(kogpt2_tokenizer, \"'1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
